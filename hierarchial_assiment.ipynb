{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf32eec-94fa-481c-8555-271a28648440",
   "metadata": {},
   "outputs": [],
   "source": [
    " '''\n",
    "Q1. What is hierarchical clustering, and how is it different from other clustering techniques?\n",
    "'''\n",
    "\n",
    "Hierarchical clustering is a clustering method that builds a hierarchy of clusters            \n",
    "in a tree-like structure called a dendrogram.\n",
    "\n",
    "Unlike other clustering techniques, hierarchical clustering does not require you\n",
    "to specify the number of clusters beforehand. \n",
    "Instead, it creates a nested set of clusters that can be cut at different levels \n",
    "to obtain different numbers of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c168a522-bc48-4c96-a864-7318fa997b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''    \n",
    "Q2. What are the two main types of hierarchical clustering algorithms? Describe each in brief.\n",
    "'''\n",
    "Two Main Approaches:\n",
    "Agglomerative: Starts with each data point as its own cluster and merges them iteratively.\n",
    "Divisive: Starts with all data points in one cluster and splits them iteratively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af7c27-5905-49cf-a21e-6e255b5b8a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q3. How do you determine the distance between two clusters in hierarchical clustering, and what are the\n",
    "common distance metrics used?\n",
    "'''\n",
    "\n",
    "\n",
    "n hierarchical clustering, the distance between two clusters is calculated using different linkage methods:\n",
    "\n",
    "Single Linkage: Shortest distance between any pair of points from the two clusters.\n",
    "Complete Linkage: Longest distance between any pair of points from the two clusters.\n",
    "Average Linkage: Average distance between all pairs of points, one from each cluster.\n",
    "Ward's Method: Based on the increase in within-cluster variance when merging clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14bbe456-d2a0-4268-8994-757ad049b3d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q4. How do you determine the optimal number of clusters in hierarchical clustering, and what are some\n",
    "common methods used for this purpose?\n",
    "'''\n",
    "\n",
    "To determine the optimal number of clusters in hierarchical clustering, you can use the following methods:\n",
    "\n",
    "Dendrogram:\n",
    "\n",
    "How it works: Cut the dendrogram at the level where the vertical distance between clusters is\n",
    "largest (longest branch), indicating a natural separation between clusters.\n",
    "Elbow Method:\n",
    "\n",
    "How it works: Plot the within-cluster variance or distance between clusters against the \n",
    "number of clusters. The \"elbow point\" where the rate of change slows suggests the optimal number of clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f357cb-7336-4416-9830-8ce720bbabaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q5. What are dendrograms in hierarchical clustering, and how are they useful in analyzing the results?\n",
    "'''\n",
    "\n",
    "A dendrogram is a tree-like diagram used in hierarchical clustering to visualize how clusters are formed.\n",
    "It shows the process of merging or splitting clusters at various levels of similarity or distance.\n",
    "\n",
    "How Dendrograms Are Useful:\n",
    "    \n",
    "Visualizing Cluster Hierarchy: Dendrograms display the entire clustering process, showing how clusters \n",
    "merge or split at different levels.\n",
    "\n",
    "Determining the Number of Clusters: By cutting the dendrogram at a specific height (distance level),\n",
    "you can decide the optimal number of clusters.\n",
    "\n",
    "Analyzing Cluster Relationships: The height of the branches indicates the distance between clusters, \n",
    "helping identify distinct groups and closely related clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e4ae55-863a-410b-8947-4f225e99394a",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q6. Can hierarchical clustering be used for both numerical and categorical data? If yes, how are the\n",
    "distance metrics different for each type of data?\n",
    "'''\n",
    "\n",
    "For Numerical Data: Use distance metrics like Euclidean or Manhattan distance.\n",
    "For Categorical Data: Use metrics like Hamming Distance or Jaccard Similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9f101-e147-40f2-945c-5092697b44f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Q7. How can you use hierarchical clustering to identify outliers or anomalies in your data?\n",
    "'''\n",
    "In hierarchical clustering, outliers or anomalies can be identified as:\n",
    "\n",
    "Isolated Clusters: Outliers may form small, distant clusters that merge with\n",
    "other clusters at a very high distance in the dendrogram.\n",
    "\n",
    "Late Mergers: Data points that are merged into larger clusters at the final\n",
    "stages (high on the dendrogram) are likely to be outliers.\n",
    "\n",
    "Dendrogram Cut: By cutting the dendrogram at an appropriate level,\n",
    "outliers may appear as small or singleton clusters."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
